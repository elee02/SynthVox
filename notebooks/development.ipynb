{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Speech saved to ../data/gen/test9.wav\n"
     ]
    }
   ],
   "source": [
    "# Step 1: Install dependencies\n",
    "# Run these commands in your terminal or notebook\n",
    "# !pip install onnxruntime phonemizer torch numpy scipy munch\n",
    "\n",
    "# Step 2: Import required libraries\n",
    "import numpy as np\n",
    "import torch\n",
    "from onnxruntime import InferenceSession\n",
    "from phonemizer import phonemize\n",
    "from pathlib import Path\n",
    "\n",
    "# Step 3: Define helper functions (from kokoro.py)\n",
    "def normalize_text(text):\n",
    "    # Normalize text (e.g., replace special characters, handle numbers, etc.)\n",
    "    # This is a simplified version; replace with the full function from kokoro.py\n",
    "    text = text.replace(\"’\", \"'\").replace(\"‘\", \"'\")\n",
    "    text = text.replace(\"“\", '\"').replace(\"”\", '\"')\n",
    "    return text\n",
    "\n",
    "def get_vocab():\n",
    "    # Define the vocabulary (replace with the full function from kokoro.py)\n",
    "    _pad = \"$\"\n",
    "    _punctuation = ';:,.!?¡¿—…\"«»“” '\n",
    "    _letters = 'ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyz'\n",
    "    _letters_ipa = \"ɑɐɒæɓʙβɔɕçɗɖðʤəɘɚɛɜɝɞɟʄɡɠɢʛɦɧħɥʜɨɪʝɭɬɫɮʟɱɯɰŋɳɲɴøɵɸθœɶʘɹɺɾɻʀʁɽʂʃʈʧʉʊʋⱱʌɣɤʍχʎʏʑʐʒʔʡʕʢǀǁǂǃˈˌːˑʼʴʰʱʲʷˠˤ˞↓↑→↗↘'̩'ᵻ\"\n",
    "    symbols = [_pad] + list(_punctuation) + list(_letters) + list(_letters_ipa)\n",
    "    return {s: i for i, s in enumerate(symbols)}\n",
    "\n",
    "VOCAB = get_vocab()\n",
    "\n",
    "def tokenize(phonemes):\n",
    "    # Convert phonemes to tokens using the vocabulary\n",
    "    return [VOCAB[p] for p in phonemes if p in VOCAB]\n",
    "\n",
    "# Step 4: Load the ONNX model\n",
    "onnx_model_path = \"../SynthVox/models/kokoro-v0_19.onnx\"\n",
    "sess = InferenceSession(onnx_model_path)\n",
    "\n",
    "# Step 5: Phonemize and tokenize the input text\n",
    "def generate_speech(text, voicepack_path, lang=\"en-us\"):\n",
    "    # Normalize the text\n",
    "    text = normalize_text(text)\n",
    "\n",
    "    # Phonemize the text\n",
    "    phonemes = phonemize(\n",
    "        text,\n",
    "        language=lang,\n",
    "        backend=\"espeak\",\n",
    "        with_stress=True,\n",
    "        preserve_punctuation=True,\n",
    "    )\n",
    "\n",
    "    # Tokenize the phonemes\n",
    "    tokens = tokenize(phonemes)\n",
    "\n",
    "    # Ensure the tokens are within the context length (510 tokens max)\n",
    "    if len(tokens) > 510:\n",
    "        tokens = tokens[:510]\n",
    "        print(\"Warning: Input text was truncated to 510 tokens.\")\n",
    "\n",
    "    # Add padding tokens (0) at the start and end\n",
    "    tokens = [0] + tokens + [0]\n",
    "\n",
    "    # Step 6: Load the voicepack\n",
    "    voicepack = torch.load(voicepack_path, weights_only=True)\n",
    "    ref_s = voicepack[len(tokens)].numpy()  # Style vector based on token length\n",
    "\n",
    "    # Step 7: Run inference with the ONNX model\n",
    "    inputs = {\n",
    "        \"tokens\": np.array([tokens], dtype=np.int64),  # Shape: (1, <=512)\n",
    "        \"style\": ref_s,  # Shape: (1, 256)\n",
    "        \"speed\": np.array([1.0], dtype=np.float32),  # Speed control (1.0 = normal)\n",
    "    }\n",
    "\n",
    "    # Generate audio\n",
    "    audio = sess.run(None, inputs)[0]  # Shape: (1, audio_length)\n",
    "\n",
    "    # Step 8: Save or play the audio\n",
    "    return audio\n",
    "\n",
    "# Step 9: Example usage\n",
    "if __name__ == \"__main__\":\n",
    "    # Input text\n",
    "    text = \"We are going to win this competition!\"\n",
    "\n",
    "    # Voicepack path (replace with the desired voicepack)\n",
    "    voicepack_path = \"../SynthVox/models/voices/af.pt\"  # Default voice (50-50 mix of Bella & Sarah)\n",
    "\n",
    "    # Generate speech\n",
    "    audio = generate_speech(text, voicepack_path)\n",
    "\n",
    "    # Save the audio to a file\n",
    "    output_file = \"../data/gen/test9.wav\"\n",
    "    import scipy.io.wavfile as wav\n",
    "    wav.write(output_file, rate=24000, data=audio.squeeze())\n",
    "\n",
    "    print(f\"Speech saved to {output_file}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
